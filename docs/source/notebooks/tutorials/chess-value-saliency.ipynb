{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess Value Saliency\n",
    "\n",
    "This notebook demonstrates how to use tdhook's Saliency to compute attribution maps for chess model predictions, showing which squares on the board are most important for the model's decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "DEV = True\n",
    "\n",
    "if importlib.util.find_spec(\"google.colab\") is not None:\n",
    "    MODE = \"colab-dev\" if DEV else \"colab\"\n",
    "else:\n",
    "    MODE = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"colab\":\n",
    "    %pip install -q tdhook lczerolens\n",
    "elif MODE == \"colab-dev\":\n",
    "    !rm -r tdhook\n",
    "    !git clone https://github.com/Xmaster6y/tdhook -b main\n",
    "    %pip install -q ./tdhook lczerolens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict import TensorDict\n",
    "from lczerolens import LczeroModel, LczeroBoard\n",
    "from tdhook.attribution import Saliency\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Set Up Board Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a chess model from HuggingFace\n",
    "model = LczeroModel.from_hf(\"lczerolens/maia-1100\")\n",
    "\n",
    "# Set up a chess position\n",
    "fen = \"5k2/2R5/1PQ5/2Pp1n2/5P2/2b1r3/3K2P1/8 w - - 11 42\"\n",
    "board = LczeroBoard(fen)\n",
    "\n",
    "moves = \"d2c2 f5d4 c2b1\"\n",
    "for move in moves.split(\" \"):\n",
    "    board.push_uci(move)\n",
    "\n",
    "print(f\"Board position after moves: {moves}\")\n",
    "print(f\"FEN: {board.fen()}\")\n",
    "\n",
    "td = model(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Saliency for Best Move\n",
    "\n",
    "We'll compute which squares are most important for the model's best move prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that extracts the best move logit as the target for attribution\n",
    "def best_logit_init_targets(td: TensorDict, _):\n",
    "    policy = td[\"policy\"]\n",
    "    best_logit = policy.max(dim=-1).values\n",
    "    return TensorDict(out=best_logit, batch_size=td.batch_size)\n",
    "\n",
    "\n",
    "# Compute saliency\n",
    "saliency_context = Saliency(init_attr_targets=best_logit_init_targets)\n",
    "with saliency_context.prepare(model) as hooked_model:\n",
    "    output = hooked_model(td)\n",
    "\n",
    "    # Get the best move\n",
    "    move = board.decode_move(output[\"policy\"][0].argmax())\n",
    "    arrows = [(move.from_square, move.to_square)]\n",
    "    print(f\"Best move: {move}\")\n",
    "\n",
    "    # Get attribution for board squares\n",
    "    batch_index = 0\n",
    "    plane = 1\n",
    "\n",
    "    svg_board, svg_colorbar = board.render_heatmap(\n",
    "        output.get((\"attr\", \"board\"))[batch_index, plane].view(64).detach(), arrows=arrows, normalise=\"abs\"\n",
    "    )\n",
    "    display(HTML(f\"{svg_board}{svg_colorbar}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Saliency for Win/Draw/Lose Predictions\n",
    "\n",
    "Now we'll compute saliency for the model's win/draw/lose (WDL) predictions to see which squares influence the outcome evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create init_targets for WDL predictions\n",
    "def get_init_targets(idx: int):\n",
    "    def init_targets(td, _):\n",
    "        return TensorDict(out=td[\"wdl\"][..., idx], batch_size=td.batch_size)\n",
    "\n",
    "    return init_targets\n",
    "\n",
    "\n",
    "batch_index = 0\n",
    "plane = 1\n",
    "\n",
    "# Compute saliency for win, draw, and lose predictions\n",
    "for idx, name in enumerate([\"win\", \"draw\", \"lose\"]):\n",
    "    print(f\"\\nComputing {name} saliency...\")\n",
    "    saliency_context = Saliency(init_attr_targets=get_init_targets(idx))\n",
    "    with saliency_context.prepare(model) as hooked_model:\n",
    "        output = hooked_model(td)\n",
    "        wdl_value = output[\"wdl\"][0, idx].item()\n",
    "        print(f\"{name.capitalize()} probability: {wdl_value:.2f}\")\n",
    "\n",
    "        # Get attribution for board squares\n",
    "        svg_board, svg_colorbar = board.render_heatmap(\n",
    "            output.get((\"attr\", \"board\"))[batch_index, plane].view(64).detach(), normalise=\"abs\"\n",
    "        )\n",
    "        display(HTML(f\"{svg_board}{svg_colorbar}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Results\n",
    "\n",
    "The saliency maps show which squares on the chess board are most important for the model's predictions:\n",
    "\n",
    "- **Best move saliency**: Highlights squares that influence which move the model considers best\n",
    "- **Win/Draw/Lose saliency**: Shows which squares affect the model's evaluation of the game outcome\n",
    "\n",
    "The attribution values indicate how much each square contributes to the prediction, with higher absolute values indicating greater importance. Positive values suggest the square increases the target value (e.g., makes a win more likely), while negative values suggest it decreases it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
