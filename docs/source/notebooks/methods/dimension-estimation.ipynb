{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsic Dimension Estimation\n",
    "\n",
    "This notebook demonstrates how to use the intrinsic dimension estimators from tdhook on synthetic data and MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "DEV = True\n",
    "\n",
    "if importlib.util.find_spec(\"google.colab\") is not None:\n",
    "    MODE = \"colab-dev\" if DEV else \"colab\"\n",
    "else:\n",
    "    MODE = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"colab\":\n",
    "    %pip install -q tdhook scikit-learn\n",
    "elif MODE == \"colab-dev\":\n",
    "    !rm -rf tdhook\n",
    "    !git clone https://github.com/Xmaster6y/tdhook -b main\n",
    "    %pip install -q ./tdhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tdhook.latent.dimension_estimation import (\n",
    "    TwoNnDimensionEstimator,\n",
    "    LocalKnnDimensionEstimator,\n",
    "    LocalPcaDimensionEstimator,\n",
    "    CaPcaDimensionEstimator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Synthetic Data (Simple Case)\n",
    "\n",
    "We start with simple synthetic manifolds where we know the true intrinsic dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generate and visualize synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# 2D plane embedded in 10D (last 8 dims zero) - intrinsic dim = 2\n",
    "plane_data = torch.randn(200, 10)\n",
    "plane_data[:, 2:] = 0\n",
    "\n",
    "# 1D circle embedded in 2D - intrinsic dim = 1\n",
    "theta = torch.rand(200) * 2 * torch.pi\n",
    "circle_data = torch.stack([torch.cos(theta), torch.sin(theta)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].scatter(plane_data[:, 0].numpy(), plane_data[:, 1].numpy(), alpha=0.6)\n",
    "axes[0].set_title(\"2D plane in 10D (first 2 dims)\")\n",
    "axes[0].set_xlabel(\"$x_1$\")\n",
    "axes[0].set_ylabel(\"$x_2$\")\n",
    "axes[0].set_aspect(\"equal\")\n",
    "\n",
    "axes[1].scatter(circle_data[:, 0].numpy(), circle_data[:, 1].numpy(), alpha=0.6)\n",
    "axes[1].set_title(\"1D circle in 2D\")\n",
    "axes[1].set_xlabel(\"$x_1$\")\n",
    "axes[1].set_ylabel(\"$x_2$\")\n",
    "axes[1].set_aspect(\"equal\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Run all estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_estimators(data, k=5):\n",
    "    td = TensorDict({\"data\": data}, batch_size=[])\n",
    "    results = {}\n",
    "\n",
    "    # TwoNN: single scalar per dataset\n",
    "    twonn = TwoNnDimensionEstimator(return_xy=True)\n",
    "    td_twonn = twonn(td.clone())\n",
    "    results[\"TwoNN\"] = td_twonn[\"dimension\"].item()\n",
    "    results[\"TwoNN_xy\"] = (td_twonn[\"dimension_x\"], td_twonn[\"dimension_y\"])\n",
    "\n",
    "    # Per-point estimators\n",
    "    for name, est in [\n",
    "        (\"LocalKnn\", LocalKnnDimensionEstimator(k=k)),\n",
    "        (\"LocalPCA\", LocalPcaDimensionEstimator(k=k)),\n",
    "        (\"CaPca\", CaPcaDimensionEstimator(k=k)),\n",
    "    ]:\n",
    "        td_est = est(td.clone())\n",
    "        d = td_est[\"dimension\"]\n",
    "        valid = torch.isfinite(d)\n",
    "        results[name] = d[valid].mean().item() if valid.any() else float(\"nan\")\n",
    "        results[f\"{name}_per_point\"] = d\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_results = run_estimators(plane_data)\n",
    "circle_results = run_estimators(circle_data)\n",
    "\n",
    "print(\"2D plane (expected ~2):\")\n",
    "for name in [\"TwoNN\", \"LocalKnn\", \"LocalPCA\", \"CaPca\"]:\n",
    "    print(f\"  {name}: {plane_results[name]:.2f}\")\n",
    "\n",
    "print(\"\\n1D circle (expected ~1):\")\n",
    "for name in [\"TwoNN\", \"LocalKnn\", \"LocalPCA\", \"CaPca\"]:\n",
    "    print(f\"  {name}: {circle_results[name]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 TwoNN visualization\n",
    "\n",
    "TwoNN estimates dimension from the linear relationship $y = d \\cdot x$ where $x = \\log(\\mu)$ and $y = -\\log(1-F)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plane = plane_results[\"TwoNN_xy\"][0].numpy()\n",
    "y_plane = plane_results[\"TwoNN_xy\"][1].numpy()\n",
    "d_plane = plane_results[\"TwoNN\"]\n",
    "valid = np.isfinite(x_plane) & np.isfinite(y_plane)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(x_plane[valid], y_plane[valid], alpha=0.6, label=\"data\")\n",
    "x_line = np.linspace(x_plane[valid].min(), x_plane[valid].max(), 50)\n",
    "ax.plot(x_line, d_plane * x_line, \"r-\", lw=2, label=f\"y = {d_plane:.2f} * x\")\n",
    "ax.set_xlabel(\"$x = \\\\log(\\\\mu)$\")\n",
    "ax.set_ylabel(\"$y = -\\\\log(1-F)$\")\n",
    "ax.set_title(\"TwoNN: 2D plane (slope = estimated dimension)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Per-point estimator histograms\n",
    "\n",
    "Per-point estimators (LocalKnn, LocalPCA, CaPca) give a dimension estimate at each data point. The box plot shows the distribution of these local estimates, revealing variation across the manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "for ax, name in zip(axes, [\"LocalKnn\", \"LocalPCA\", \"CaPca\"]):\n",
    "    d = plane_results[f\"{name}_per_point\"].numpy()\n",
    "    valid = np.isfinite(d)\n",
    "    ax.hist(d[valid], bins=20, edgecolor=\"black\", alpha=0.7)\n",
    "    ax.axvline(plane_results[name], color=\"red\", linestyle=\"--\", label=f\"mean = {plane_results[name]:.2f}\")\n",
    "    ax.set_xlabel(\"Estimated dimension\")\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle(\"Per-point dimension estimates on 2D plane\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: MNIST\n",
    "\n",
    "We now run the estimators on MNIST digits. The intrinsic dimension of the MNIST manifold is typically around 10-15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mnist\", split=\"train\")\n",
    "arr = np.array(ds[\"image\"][:1000])\n",
    "mnist_data = torch.tensor(arr, dtype=torch.float32).reshape(1000, -1) / 255.0\n",
    "\n",
    "print(f\"MNIST shape: {mnist_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sample digits visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = mnist_data[i].reshape(28, 28).numpy()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Sample MNIST digits\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run estimators on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_results = run_estimators(mnist_data, k=\"auto\")\n",
    "\n",
    "print(\"MNIST (expected ~10-15):\")\n",
    "for name in [\"TwoNN\", \"LocalKnn\", \"LocalPCA\", \"CaPca\"]:\n",
    "    print(f\"  {name}: {mnist_results[name]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 TwoNN curve fitting on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mnist = mnist_results[\"TwoNN_xy\"][0].numpy()\n",
    "y_mnist = mnist_results[\"TwoNN_xy\"][1].numpy()\n",
    "d_mnist = mnist_results[\"TwoNN\"]\n",
    "valid = np.isfinite(x_mnist) & np.isfinite(y_mnist)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(x_mnist[valid], y_mnist[valid], alpha=0.6, label=\"data\")\n",
    "x_line = np.linspace(x_mnist[valid].min(), x_mnist[valid].max(), 50)\n",
    "ax.plot(x_line, d_mnist * x_line, \"r-\", lw=2, label=f\"y = {d_mnist:.2f} * x\")\n",
    "ax.set_xlabel(\"$x = \\\\log(\\\\mu)$\")\n",
    "ax.set_ylabel(\"$y = -\\\\log(1-F)$\")\n",
    "ax.set_title(\"TwoNN: MNIST (slope = estimated dimension)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Box plot: per-point estimators (local variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_point_methods = [\"LocalKnn\", \"LocalPCA\", \"CaPca\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, name in zip(axes, per_point_methods):\n",
    "    d = mnist_results[f\"{name}_per_point\"].numpy()\n",
    "    d = d[np.isfinite(d)]\n",
    "    bp = ax.boxplot([d], tick_labels=[name], patch_artist=True)\n",
    "    ax.axhline(12, color=\"gray\", linestyle=\"--\", alpha=0.7, label=\"typical MNIST ~12\")\n",
    "    ax.set_ylabel(\"Estimated dimension (per point)\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle(\"Per-point dimension estimates on MNIST (1000 images)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
